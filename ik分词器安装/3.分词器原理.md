ik分词器的主要逻辑包括三部分：
1）词典：词典的好坏直接影响分词结果的好坏，本文将介绍词典的构建和存储结构 
2）词的匹配：有了词典之后，就可以对输入的字符串逐字句和词典进行匹配
3）消除歧义：通过词典匹配出来的切分方式会有多种，消除歧义就是从中寻找最合理的一种方式


三种常见的词典分别是：
1）main.dic：主词典，一些常用词
2）quantifier.dic：常用的量词
3）stopword.dic：停用词
这些词典用户都可以自行扩展，只需要配置IKAnalyzer.cfg.xml文件即可
词典是怎么加载的呢，常用的字典树 tire tree 是一种结构简单的树，也叫做前缀树

从根节点触发，把一个词挂在这颗树上。其中词的开头，都是根节点的孩子节点，每个字都是前一个字的孩子节点，红色的节点表示词的结尾。
由于main.dic的词非常多，而且用户又可以自定义扩展，这样会导致这个树会非常庞大，如果存粹用map存储，会比较浪费空间，因此ik采用了一种折中的方式。

根据子节点的数量对存储结构进行调整，如果子节点的数量小于等于3，则采用数组存储，如果子节点的数量大于3，采用map存储。


切词
有了词典和输入语句之后，就可以进行切词了。ik的切词方式主要有两种，一种为smart模式，一种为ik_max_word即非smart模式

从非smart的分词结果中可以看出，对于一个语句可以有很多种切分方式，非smart就是把没种可能的分词结果都给出来了。而smart模式，就是需要在这几种分词模式中，寻找一种认为最合理的分词方式。


从处理角度说，设置了smart模式，就是在进行词切分后，在进行一次分词的选择，即通常说的消除歧义。
ik默认实现了三种分词器，分别为CJKSegmenter（中文-日韩文子分词器）、CN_QuantifierSegmenter（中文数量词分词器）、LetterSegmenter（英文字符及阿拉伯数字子分词器）。

首先是LetterSegmenter，英文分词器比较简单，就是把连续的英文字符，或者连续的数据进行分词。
然后是CN_QuantifierSegmenter，量词分词器。主要是判断当前的字符是否是数词和量词，会把连起来的数词和量词分成一个词。
最主要的是CJKSegmenter，该分词器就是基于词典匹配的。

https://juejin.cn/post/6845166891120476168

https://juejin.cn/post/6844903848323072007

https://segmentfault.com/a/1190000017215854